{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color:\n",
    "    BLACK = \"\\033[30m\"\n",
    "    RED = \"\\033[31m\"\n",
    "    GREEN = \"\\033[32m\"\n",
    "    YELLOW = \"\\033[33m\"\n",
    "    BLUE = \"\\033[34m\"\n",
    "    MAGENTA = \"\\033[35m\"\n",
    "    CYAN = \"\\033[36m\"\n",
    "    WHITE = \"\\033[37m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "c = Color()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m+              SPAM OR HAM PROJECT                  +\n",
      "\u001b[36m+       AML2203 Midterm Project - Group 3           +\n",
      "\u001b[36m+++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def launchProgram():\n",
    "    print(f\"{c.CYAN}+++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"{c.CYAN}+              SPAM OR HAM PROJECT                  +\")\n",
    "    print(f\"{c.CYAN}+       AML2203 Midterm Project - Group 3           +\")\n",
    "    print(f\"{c.CYAN}+++++++++++++++++++++++++++++++++++++++++++++++++++++{c.RESET}\\n\")\n",
    "\n",
    "launchProgram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m Count of Dataset: \u001b[0m\n",
      " id           5171\n",
      "label        5171\n",
      "text         5171\n",
      "label_num    5171\n",
      "dtype: int64\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5171 entries, 0 to 5170\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         5171 non-null   int64 \n",
      " 1   label      5171 non-null   object\n",
      " 2   text       5171 non-null   object\n",
      " 3   label_num  5171 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 161.7+ KB\n",
      "\u001b[32m Info of Dataset: \u001b[0m\n",
      " None\n",
      "\n",
      "\u001b[32m Data Frame Shape: \u001b[0m\n",
      " (5171, 4)\n",
      "\n",
      "\u001b[32m Preview of Dataset: \u001b[0m\n",
      "      id label                                               text  label_num\n",
      "0   605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
      "1  2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
      "2  3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
      "3  4685  spam  Subject: photoshop , windows , office . cheap ...          1\n",
      "4  2030   ham  Subject: re : indian springs\\r\\nthis deal is t...          0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"spam_dataset.csv\")\n",
    "print(f\"{c.GREEN} Count of Dataset: {c.RESET}\\n {df.count()}\\n\") # Displays the count of records available for a particular field\n",
    "print(f\"{c.GREEN} Info of Dataset: {c.RESET}\\n {df.info()}\\n\") # Displays the information on the data set includes the index number, column name, non-null columns and data type\n",
    "###To be checked on why the label is displayed at the bottom of the result of df.info()\n",
    "print(f\"{c.GREEN} Data Frame Shape: {c.RESET}\\n {df.shape}\\n\") # Displays the dimension of the data which is 5171 rows and 4 columns\n",
    "print(f\"{c.GREEN} Preview of Dataset: {c.RESET}\\n {df.head()}\\n\") # Displays a preview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text column into numerical features using the bag-of-words model\n",
    "vectorizer = CountVectorizer() # Creates an instance of the CountVectorizer class, a tool for converting a collection of text documents into a matrix of token counts\n",
    "X = vectorizer.fit_transform(df[\"text\"]) # Fits the CountVectorizer to the text data in the \"text\" column of the df DataFrame and transforms the text data into a sparse matrix of word counts, which is assigned to the variable X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag of words model is a way of representing text data in a numerical format for use in machine learning and natural language processing (NLP) tasks. In this model, a piece of text is represented as a bag (or multiset) of its constituent words, with each word treated as a discrete entity.\n",
    "\n",
    "To create a bag of words representation, the text is first preprocessed to remove punctuation and other irrelevant symbols, and to convert all words to lowercase. Then, each unique word in the text is assigned a numerical index. Finally, for each piece of text, a vector is created where each element corresponds to the count of the corresponding word in the text. The resulting vector is known as the bag of words representation of the text.\n",
    "\n",
    "The bag of words model is a simple and efficient way of representing text data, but it has limitations. It does not take into account the context in which the words appear or their semantic meaning, and it treats each word as independent of the others, which can result in a loss of information. However, it is still widely used in NLP tasks such as text classification, sentiment analysis, and information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df[\"label\"], test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line uses the train_test_split function from scikit-learn to split the data into training and testing sets. The X matrix contains the input data, while df[\"label\"] contains the corresponding labels for each sample in X. The test_size parameter specifies the proportion of the data that should be used for testing (in this case, 20%). The train_test_split function shuffles the data and splits it into two sets: one for training and one for testing.\n",
    "\n",
    "The resulting output consists of four arrays:\n",
    "\n",
    "X_train: The input data for the training set\n",
    "X_test: The input data for the testing set\n",
    "y_train: The corresponding labels for the training set\n",
    "y_test: The corresponding labels for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the label of the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m ***Accuracy: \u001b[0m 0.9797101449275363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"{c.GREEN} ***Accuracy: {c.RESET} {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m ***Precision Score (Macro): \u001b[0m 0.9764481390849581\n",
      "\n",
      "\u001b[32m ***Precision score (Weighted): \u001b[0m 0.9796941154147962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the precision score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "print(f\"{c.GREEN} ***Precision Score (Macro): {c.RESET} {precision_macro}\\n\")\n",
    "precision_weighted = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"{c.GREEN} ***Precision score (Weighted): {c.RESET} {precision_weighted}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both macro and weighted are options for computing the average precision score for multi-class classification problems. The difference between these two options lies in how they handle class imbalance.\n",
    "\n",
    "Macro: Computes the precision for each class independently and then takes the average of these scores, giving equal weight to each class. This means that the precision for each class is given the same importance, regardless of the number of samples in each class.\n",
    "\n",
    "Weighted: Computes the average precision score, weighted by the number of samples in each class. This means that the precision score is higher when there are more samples in a class, and lower when there are fewer samples in a class. The precision score is weighted based on the number of samples in each class, so it gives more importance to classes with more samples.\n",
    "\n",
    "In other words, macro is suitable for use when you want to give equal weight to each class, regardless of the number of samples in each class. weighted is suitable when you want to account for class imbalance and give more weight to classes with more samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Prediction Report\n",
    "# plt.scatter(X_test, y_test, color ='b')\n",
    "# plt.plot(X_test, y_pred, color ='k')\n",
    "# plt.show()\n",
    "# Data scatter of predicted values\n",
    "# print precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m***Score: \u001b[0m 0.9797101449275363\n",
      "\n",
      "\u001b[32m***Classification Report*** \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       720\n",
      "        spam       0.97      0.97      0.97       315\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.98      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "\u001b[32m***Confusion Matrix*** \u001b[0m\n",
      "[[2916   36]\n",
      " [  53 1131]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evalModel(model, X_train, X_test, y_train, y_test, y_pred): # This method evaluate the Logistic Regression model and provide clasification report, confusion matrix and precision score\n",
    "\n",
    "    print(f\"{c.GREEN}***Score: {c.RESET} {model.score(X_test, y_test)}\\n\")\n",
    "\n",
    "    # Classification Report without cross-validation\n",
    "    # For reference on classification matrix https://www.simplilearn.com/tutorials/machine-learning-tutorial/confusion-matrix-machine-learning#:~:text=A%20confusion%20matrix%20presents%20a,actual%20values%20of%20a%20classifier.\n",
    "    print(f\"{c.GREEN}***Classification Report*** {c.RESET}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # k-fold cross-validation and confusion matrices\n",
    "    y_train_pred = cross_val_predict(model, X_train, y_train, cv=5)\n",
    "    print(f\"{c.GREEN}***Confusion Matrix*** {c.RESET}\")\n",
    "    print(confusion_matrix(y_train, y_train_pred), \"\\n\")\n",
    "\n",
    "\n",
    "evalModel(model, X_train, X_test, y_train, y_test, y_pred) #This method generates the Classification Report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
